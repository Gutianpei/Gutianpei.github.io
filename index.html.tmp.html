
<!doctype html>
<html>

<head>
	<meta name="google-site-verification" content="zTvaPIARk2z5erZsE_yyEIuPe3r5Z1kwHtZ662ncmLU" />
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="chrome=1">
	<title>Tianpei Gu 顾天培</title>

	<link rel="stylesheet" href="stylesheets/styles.css">
	<link rel="stylesheet" href="stylesheets/pygment_trac.css">
	<meta name="viewport" content="width=device-width">
	<link rel="icon" type="image/png" href="images/icon.png">
	<!--[if lt IE 9]>
		<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
		<![endif]-->
</head>

<body>
	<div class="wrapper">
		<header>
			<h2>Tianpei Gu 「顾天培」</h2>
			<p></p>
			<p>Research Intern @ Tsinghua University</p>
			<img src="images/tianpei.JPG" alt="Photo @ UMD.">
			<p>
				<b>Email:</b> <a href="mailto:brucegu@umd.edu">brucegu@umd.edu</a><br>
				<b>Github:</b> <a href="https://github.com/Gutianpei" , target="_blank">https://github.com/Gutianpei</a><br>
				<b>LinkedIn:</b> <a href="https://www.linkedin.com/in/tianpei-gu-973904129/ ,
					target="_blank">https://www.linkedin.com/in/tianpei-gu-973904129/</a><br>
			</p>
			<img src="images/umd.jpg" alt="umd." height=63 weight = 63>
			<img src="images/thu.png" alt="thu." height=57 weight = 57>
			

		</header>
		<section>
			<h1>About Me</h1>
			<p> I'm a Resaerch Assistant at <a href="http://ivg.au.tsinghua.edu.cn/">Intelligent Vision Group (IVG)</a>,  <b>Tsinghua University</b>, under the guidance of <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Prof. Jiwen Lu</a>. I also worked at <b>SenseTime Research</b> as an intern now. In December 2020, I received B.S. degree in Computer Science and Mathematics at the University of Maryland. Before joined IVG, I did research at <a href="http://prg.cs.umd.edu/">Perception and Robotics Group (PRG)</a> in the <a href="https://www.cs.umd.edu/">Department of Computer Science</a>, <b>University of Maryland</b>, under the guidance of <a href="http://legacydirs.umiacs.umd.edu/~yiannis/">Prof. Yiannis Aloimonos</a>.
				My research interest is in <b>Computer Vision</b>, especially <b>Person Re-identification</b> and <b>Causal Inference</b>. I spent time at SenseTime Research. 
<!-- 				You can find my <a href="docs/GTP CV.pdf" target="_blank">resume</a> here. -->
			</p>
			<h1>Education</h1>
			
			<h3>University of California, Los Angeles, CA, USA</h3>
			<ul>
				<li>Incoming Master student in Engeering</li>
			</ul>

			<h3>University of Maryland at College Park, MD, USA</h3>
			<ul>
				<li>Bachelor of Science in Computer Science</li>
				<li>Bachelor of Science in Mathematics</li>
				<li>GPA: 3.7</li>
			</ul>

			<h1>Publications</h1>
			<td width="75%" valign="center">
				<strong>[1] Person Re-Identification via Attention Pyramid</strong>
				<br>
				Guangyi Chen, <strong>Tianpei Gu</strong>, Jiwen Lu, Jin-an Bao, Jie Zhou
				<br>
				<em>Submitted to IEEE Transcations on Image Processing(<strong>TIP</strong>), 2020</em>
				<p>We designed a novel attention pyarmid structure to help the network focus more on local feature while keep the global representation.</p>
			</td>
<!-- 			<td width="75%" valign="center"> -->
<!-- 				<strong>[2] Learnable Re-Ranking for Image Retrieval</strong> -->
<!-- 				<br> -->
<!-- 				<strong>Tianpei Gu</strong>, Guangyi Chen, Jiwen Lu, Jie Zhou -->
<!-- 				<br> -->
<!-- 				<em>Submitted to the IEEE/CVF International Conference on Computer Vision(<strong>ICCV</strong>), 2021</em> -->
<!-- 				<p>We proposed a Graph Neural Network to formulate re-ranking as a learnable process.</p> -->
<!-- 			</td> -->
			
			
			<h1>Research Experience</h1>
			<h2>Current Project</h2>	
			<h3>Diffusion Model for Generative Task</h3>
			<ul>
				<li>Exploring the current Diffusion Probabilistic Models and its future application or limitation</li>
			</ul>
			
			<h3>Image Editting and Translating</h3>
			<ul>
				<li>Exploring the latent space of GAN and proposing a transformer-based method to find a more fine-grained solution for image manupulating.</li>
				<li>Working with SenseTime Research</li>
			</ul>
			
			<h3>Music to Dance</h3>
			<ul>
				<li>Generating 3D dance pose from input music.</li>
				<li>Working with SenseTime Research</li>
			</ul>
			
			
			
			
			<h2>Past Project</h2>		
			<h3>3-D Reconstruction</h3>
			<ul>
				<li>Researching on state-of-art 3D Reconstruction method, especially reconstruct with <a href="https://smpl.is.tue.mpg.de/">SMPL model</a>.</li>
				<li>Customized existing 3D construction methods to fit our dataset; maintained the human 3D reconstruction methods survey for the lab. </li>
			</ul>
			
<!-- 			<h3>Image-to-Image Translation</h3> -->
<!-- 			<ul> -->
<!-- 				<li>Completely replicated the result of the paper U-GAT-IT and AniGAN and implement the model to real-world products. Both methods have no open-sourced code in Pytorch and I implement them from scratch</li> -->
<!-- 				<li>Ongoing</li> -->
<!-- 			</ul> -->
			
			<h3>Person Re-identification</h3>
			<ul>
				<li>Proposed a novel CNN-based network to re-identify person based on their movement style. </li>
				<li>Built an online and in-memory system to re-identify people with 85% accuracy under clean image setting.</li>
				<li>Propose to draw the counterfactual causality from the traditional trained "biased" network to infer the effect from bad bias, then remove them. Proposed a novel deep neural network for Person Re-ID task to make causal intervention in training and counterfactual reasoning in inference to remove the bad while keep the good features. </li>
				<li>Proposed an attention pyramid structure for Person Re-ID task to focus more on local attention of the feature map while keep the global attention of a human image. Our method outperforms the state-of-the-art methods by a large margin with -40% computational cost. The work has been submitted to TIP.</li>
			</ul>
			
<!-- 			<h3>Text-based Person Search</h3> -->
<!-- 			<ul> -->
<!-- 				<li>Proposed a novel CNN-based network for text-based person search, using Resnet50 and Bi-LSTM as backbone network</li> -->
<!-- 				<li>Improved performance by adding Batch Normalization and Instance Normalization layers into our network and employing the triplet loss as the loss function. Our method outperforms the current state-of-the-art methods.</li> -->
<!-- 			</ul> -->
			
			
			<h1>Field Experience</h1>
			
			<h3>SenseTime Research</h3>
			Computer Vision Research Intern
			<ul>
				<li>Build an end-to-end image generation pipeline using StyleGANv2 to produce massive high-quality paired image in given style.</li>
				<li>Proposed to provide a fine-grained solution for face image editting using Transformer</li>
				<li>Proposed a multi-style-transfer network using StyleGAN and current GAN inversion networks</li>
				<li>Assisted to implement the project of music to dance generation</li>
			</ul>

			
			
			
			<h3>Beijing Photon Dance Tech Inc.</h3>
			Co-Founder, Algorithm Engineer
			<ul>
				<li>Founded in Skywork Team, Tsinghua University.</li>
				<li>Proposed an end-to-end solution from extracted 3D point cloud with multiple views to automatic motion difference evaluating. Participated in multi-view point cloud calibration and developing of DL-based merging algorithm.</li>
				<li>Our team just receive the Pre-A Investment.</li>
			</ul>

			<h1>Professional Skills</h1>
			<p><b>Programming Language (ranked by proficiency):</b> Python, Java, C, C++, Matlab, Git, Shell</p>
			<p><b>Deep Learning Framework:</b> Keras, PyTorch, TensorFlow </p>


		</section>
		<footer>
			<p>
				<small>
					Hosted on GitHub Pages &mdash;
					Theme by <a href="https://github.com/orderedlist" , target="_blank">orderedlist</a>.
					<!-- <span id="busuanzi_container_site_pv" style='display:none'>
						Viewed <span id="busuanzi_value_site_pv"></span> times.
					</span> -->
				</small>
			</p>
		</footer>
	</div>
	<script src="javascripts/scale.fix.js"></script>
	<script async src="http://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>
</body>

</html>
